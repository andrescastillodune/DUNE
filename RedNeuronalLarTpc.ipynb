{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we train a simple, 10-layers deep convolutional neural network for classifying 5 particle images in a simulated LArTPC detecotr available from the public dataset. We use tensorflow to train the network and larcv_threadio to fetch data from larcv files. If you are completely unfamiliar with larcv_threadio, go look at this quick start. First let's prepare data samples. For the setup of this example, I need to prepare practice_train_5k.root and practice_test_5k.root in the current directory. Let us make symbolic links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Preparation: make symbolic links for practice_train_10k.root and practice_test_10k.root\n",
    "PRACTICE_FILE_DIR=/home/dell/larcv2/C1/\n",
    "ln -sf $PRACTICE_FILE_DIR/practice_train_5k.root ./train.root\n",
    "ln -sf $PRACTICE_FILE_DIR/practice_test_5k.root ./test.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.19/01\n"
     ]
    }
   ],
   "source": [
    "from larcv import larcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from larcv.dataloader2 import larcv_threadio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os,sys,time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# tensorflow/gpu start-up configuration\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set os.environ['TF_CPP_MIN_LOG_LEVEL'] to suppress lots of non-error (standard) output from tensorflow because it can overwhelm ipython's capability to fetch stdout stream.\n",
    "\n",
    "# Configurations\n",
    "Next, let's define configuration variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_DIR     = '/home/dell/larcv2/larcv-tutorial/'\n",
    "TRAIN_IO_CONFIG  = os.path.join(TUTORIAL_DIR, 'tf/io_train.cfg')\n",
    "TEST_IO_CONFIG   = os.path.join(TUTORIAL_DIR, 'tf/io_test.cfg' )\n",
    "TRAIN_BATCH_SIZE = 50\n",
    "TEST_BATCH_SIZE  = 100\n",
    "LOGDIR           = 'log'\n",
    "ITERATIONS       = 5000\n",
    "SAVE_SUMMARY     = 20\n",
    "SAVE_WEIGHTS     = 100\n",
    "\n",
    "# Check log directory is empty\n",
    "train_logdir = os.path.join(LOGDIR,'train')\n",
    "test_logdir  = os.path.join(LOGDIR,'test')\n",
    "if not os.path.isdir(train_logdir): os.makedirs(train_logdir)\n",
    "if not os.path.isdir(test_logdir):  os.makedirs(test_logdir)\n",
    "if len(os.listdir(train_logdir)) or len(os.listdir(test_logdir)):\n",
    "  sys.stderr.write('Error: train or test log dir not empty...\\n')\n",
    "  raise OSError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top block defines a set of constants in capitalized letters. The bottom part is simply checking if the directories where we will store the network training logs are empty or not (so that we won't mix with the previous attempt). So what do the constants do?\n",
    "\n",
    "TUTORIAL_DIR ... points to the top-level directory of the larcv-tutorial repostitory.\n",
    "TRAIN_IO_CONFIG ... a configuration file for larcv_threadio to read data for training.\n",
    "TEST_IO_CONFIG ... a configuration file for larcv_threadio to read data for testing.\n",
    "TRAIN_BATCH_SIZE ... a number of images (batch) to be used to calculate the average gradients for updating the network's weights.\n",
    "TEST_BATCH_SIZE ... a number of images to be used to calculate the average accuracy using test data set.\n",
    "LOGDIR ... the top-level directory to save the tensorboard logs.\n",
    "ITERATIONS ... the total number of steps (batches) to train the network.\n",
    "SAVE_SUMMARY ... a period in a training step count to save the log (tensorboard summaries).\n",
    "SAVE_WEIGHTS ... a period in a training step count to save the network's weights.\n",
    "\n",
    "# Configure data reader\n",
    "We prepare two data reader instances: one for training and another for testing the network. Testing is not absolutely needed but we try here to just cover in this example. We don't go in details of how larcv_threadio works here since there is a dedicated tutorial for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m setting verbosity \u001b[00m3\n",
      "\u001b[93m setting verbosity \u001b[00m3\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 0: IO\n",
    "#\n",
    "# for \"train\" data set\n",
    "train_io = larcv_threadio()  # create io interface\n",
    "train_io_cfg = {'filler_name' : 'TrainIO',\n",
    "                'verbosity'   : 0,\n",
    "                'filler_cfg'  : TRAIN_IO_CONFIG}\n",
    "train_io.configure(train_io_cfg)   # configure\n",
    "train_io.start_manager(TRAIN_BATCH_SIZE) # start read thread\n",
    "time.sleep(2)\n",
    "train_io.next()\n",
    "\n",
    "# for \"test\" data set\n",
    "test_io = larcv_threadio()   # create io interface\n",
    "test_io_cfg = {'filler_name' : 'TestIO',\n",
    "               'verbosity'   : 0,\n",
    "               'filler_cfg'  : TEST_IO_CONFIG}\n",
    "test_io.configure(test_io_cfg)   # configure\n",
    "test_io.start_manager(TEST_BATCH_SIZE) # start read thread\n",
    "time.sleep(2)\n",
    "test_io.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a network\n",
    "Let's construct a simple network for this exercise. We use 5x2 convolution layers with max-pooling operation followed after every 2 convolution layers except the last layer is average-pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Step 1: Define network\n",
    "#\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.python.platform\n",
    "\n",
    "\n",
    "\n",
    "def build(input_tensor, num_class=4, trainable=True, debug=True):\n",
    "\n",
    "    net = input_tensor\n",
    "    if debug: print('input tensor:', input_tensor.shape)\n",
    "\n",
    "    filters = 32\n",
    "    num_modules = 5\n",
    "    with tf.variable_scope('conv'):\n",
    "        for step in range(5):\n",
    "            stride = 2\n",
    "            if step: stride = 1\n",
    "            net = slim.conv2d(inputs        = net,        # input tensor\n",
    "                              num_outputs   = filters,    # number of filters (neurons) = # of output feature maps\n",
    "                              kernel_size   = [3,3],      # kernel size\n",
    "                              stride        = stride,     # stride size\n",
    "                              trainable     = trainable,  # train or inference\n",
    "                              activation_fn = tf.nn.relu, # relu\n",
    "                              scope         = 'conv%da_conv' % step)\n",
    "\n",
    "            net = slim.conv2d(inputs        = net,        # input tensor\n",
    "                              num_outputs   = filters,    # number of filters (neurons) = # of output feature maps\n",
    "                              kernel_size   = [3,3],      # kernel size\n",
    "                              stride        = 1,          # stride size\n",
    "                              trainable     = trainable,  # train or inference\n",
    "                              activation_fn = tf.nn.relu, # relu\n",
    "                              scope         = 'conv%db_conv' % step)\n",
    "            if (step+1) < num_modules:\n",
    "                net = slim.max_pool2d(inputs      = net,    # input tensor\n",
    "                                      kernel_size = [2,2],  # kernel size\n",
    "                                      stride      = 2,      # stride size\n",
    "                                      scope       = 'conv%d_pool' % step)\n",
    "\n",
    "            else:\n",
    "                net = tf.layers.average_pooling2d(inputs = net,\n",
    "                                                  pool_size = [net.get_shape()[-2].value,net.get_shape()[-3].value],\n",
    "                                                  strides = 1,\n",
    "                                                  padding = 'valid',\n",
    "                                                  name = 'conv%d_pool' % step)\n",
    "            filters *= 2\n",
    "\n",
    "            if debug: print('After step',step,'shape',net.shape)\n",
    "\n",
    "    with tf.variable_scope('final'):\n",
    "        net = slim.flatten(net, scope='flatten')\n",
    "\n",
    "        if debug: print('After flattening', net.shape)\n",
    "\n",
    "        net = slim.fully_connected(net, int(num_class), scope='final_fc')\n",
    "\n",
    "        if debug: print('After final_fc', net.shape)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 15:59:01.443275 139909278713664 deprecation.py:323] From <ipython-input-8-7d2490db2822>:46: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.AveragePooling2D instead.\n",
      "W0805 15:59:01.446020 139909278713664 deprecation.py:323] From /home/dell/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0805 15:59:01.849423 139909278713664 deprecation.py:323] From <ipython-input-9-2db20bc27ed7>:25: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0805 15:59:02.049957 139909278713664 deprecation.py:506] From /home/dell/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 2: Build network + define loss & solver\n",
    "#\n",
    "# retrieve dimensions of data for network construction\n",
    "tf.reset_default_graph() \n",
    "\n",
    "dim_data  = train_io.fetch_data('train_image').dim()\n",
    "dim_label = train_io.fetch_data('train_label').dim()\n",
    "# define place holders\n",
    "data_tensor    = tf.placeholder(tf.float32, [None, dim_data[1] * dim_data[2] * dim_data[3]], name='image')\n",
    "label_tensor   = tf.placeholder(tf.float32, [None, dim_label[1]], name='label')\n",
    "data_tensor_2d = tf.reshape(data_tensor, [-1,dim_data[1],dim_data[2],dim_data[3]],name='image_reshape')\n",
    "\n",
    "# Let's keep 10 random set of images in the log\n",
    "tf.summary.image('input',data_tensor_2d,10)\n",
    "# build net\n",
    "net = build(input_tensor=data_tensor_2d, num_class=dim_label[1], trainable=True, debug=False)\n",
    "# Define accuracy\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(net,1), tf.argmax(label_tensor,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "# Define loss + backprop as training step\n",
    "with tf.name_scope('train'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label_tensor, logits=net))\n",
    "    tf.summary.scalar('cross_entropy',cross_entropy)\n",
    "    train_step = tf.train.RMSPropOptimizer(0.00005).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                                                                                                      \n",
    "# Step 3: weight saver & summary writer                                                                                                \n",
    "#                                                                                                                                      \n",
    "# Create a bandle of summary                                                                                                           \n",
    "merged_summary=tf.summary.merge_all()\n",
    "# Create a session                                                                                                                     \n",
    "sess = tf.InteractiveSession()\n",
    "# Initialize variables                                                                                                                 \n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Create a summary writer handle                                                                                                       \n",
    "writer_train=tf.summary.FileWriter(train_logdir)\n",
    "writer_train.add_graph(sess.graph)\n",
    "writer_test=tf.summary.FileWriter(test_logdir)\n",
    "writer_test.add_graph(sess.graph)\n",
    "# Create weights saver                                                                                                                 \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress @ step 19 loss 1.60894 accuracy 0.28          \n",
      "Testing in progress @ step 19 loss 1.60183 accuracy 0.23          \n",
      "Training in progress @ step 39 loss 1.59624 accuracy 0.24          \n",
      "Testing in progress @ step 39 loss 1.62453 accuracy 0.1          \n",
      "Training in progress @ step 59 loss 1.58608 accuracy 0.26          \n",
      "Testing in progress @ step 59 loss 1.61284 accuracy 0.18          \n",
      "Training in progress @ step 79 loss 1.58555 accuracy 0.2          \n",
      "Testing in progress @ step 79 loss 1.57619 accuracy 0.3          \n",
      "Training in progress @ step 99 loss 1.60136 accuracy 0.18          \n",
      "Testing in progress @ step 99 loss 1.59881 accuracy 0.19          \n",
      "saved @ weights/toynet-99\n",
      "Training in progress @ step 119 loss 1.59041 accuracy 0.26          \n",
      "Testing in progress @ step 119 loss 1.59514 accuracy 0.33          \n",
      "Training in progress @ step 139 loss 1.59309 accuracy 0.24          \n",
      "Testing in progress @ step 139 loss 1.60593 accuracy 0.26          \n",
      "Training in progress @ step 159 loss 1.55793 accuracy 0.32          \n",
      "Testing in progress @ step 159 loss 1.58255 accuracy 0.26          \n",
      "Training in progress @ step 179 loss 1.54294 accuracy 0.34          \n",
      "Testing in progress @ step 179 loss 1.52417 accuracy 0.39          \n",
      "Training in progress @ step 199 loss 1.56506 accuracy 0.28          \n",
      "Testing in progress @ step 199 loss 1.46679 accuracy 0.37          \n",
      "saved @ weights/toynet-199\n",
      "Training in progress @ step 219 loss 1.63531 accuracy 0.2          \n",
      "Testing in progress @ step 219 loss 1.45836 accuracy 0.33          \n",
      "Training in progress @ step 239 loss 1.56784 accuracy 0.26          \n",
      "Testing in progress @ step 239 loss 1.48089 accuracy 0.34          \n",
      "Training in progress @ step 259 loss 1.60159 accuracy 0.3          \n",
      "Testing in progress @ step 259 loss 1.55539 accuracy 0.28          \n",
      "Training in progress @ step 279 loss 1.47303 accuracy 0.3          \n",
      "Testing in progress @ step 279 loss 1.5555 accuracy 0.29          \n",
      "Training in progress @ step 299 loss 1.37347 accuracy 0.36          \n",
      "Testing in progress @ step 299 loss 1.45492 accuracy 0.37          \n",
      "saved @ weights/toynet-299\n",
      "Training in progress @ step 319 loss 1.50788 accuracy 0.26          \n",
      "Testing in progress @ step 319 loss 1.42615 accuracy 0.41          \n",
      "Training in progress @ step 339 loss 1.36834 accuracy 0.32          \n",
      "Testing in progress @ step 339 loss 1.67414 accuracy 0.29          \n",
      "Training in progress @ step 359 loss 1.44394 accuracy 0.34          \n",
      "Testing in progress @ step 359 loss 1.44101 accuracy 0.34          \n",
      "Training in progress @ step 379 loss 1.16963 accuracy 0.5          \n",
      "Testing in progress @ step 379 loss 1.37226 accuracy 0.38          \n",
      "Training in progress @ step 399 loss 1.53225 accuracy 0.2          \n",
      "Testing in progress @ step 399 loss 1.41253 accuracy 0.32          \n",
      "saved @ weights/toynet-399\n",
      "Training in progress @ step 419 loss 1.40954 accuracy 0.42          \n",
      "Testing in progress @ step 419 loss 1.3277 accuracy 0.42          \n",
      "Training in progress @ step 439 loss 1.33096 accuracy 0.42          \n",
      "Testing in progress @ step 439 loss 1.47834 accuracy 0.31          \n",
      "Training in progress @ step 459 loss 1.60171 accuracy 0.24          \n",
      "Testing in progress @ step 459 loss 1.47409 accuracy 0.42          \n",
      "Training in progress @ step 479 loss 1.40537 accuracy 0.42          \n",
      "Testing in progress @ step 479 loss 1.58949 accuracy 0.33          \n",
      "Training in progress @ step 499 loss 1.51119 accuracy 0.26          \n",
      "Testing in progress @ step 499 loss 1.53673 accuracy 0.29          \n",
      "saved @ weights/toynet-499\n",
      "Training in progress @ step 519 loss 1.20977 accuracy 0.62          \n",
      "Testing in progress @ step 519 loss 1.55216 accuracy 0.3          \n",
      "Training in progress @ step 539 loss 1.28779 accuracy 0.4          \n",
      "Testing in progress @ step 539 loss 1.46277 accuracy 0.37          \n",
      "Training in progress @ step 559 loss 1.5145 accuracy 0.3          \n",
      "Testing in progress @ step 559 loss 1.3879 accuracy 0.42          \n",
      "Training in progress @ step 579 loss 1.47923 accuracy 0.3          \n",
      "Testing in progress @ step 579 loss 1.46012 accuracy 0.44          \n",
      "Training in progress @ step 599 loss 1.72706 accuracy 0.26          \n",
      "Testing in progress @ step 599 loss 1.42124 accuracy 0.36          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 16:39:45.732969 139909278713664 deprecation.py:323] From /home/dell/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved @ weights/toynet-599\n",
      "Training in progress @ step 619 loss 1.30643 accuracy 0.46          \n",
      "Testing in progress @ step 619 loss 1.32582 accuracy 0.49          \n",
      "Training in progress @ step 639 loss 1.28517 accuracy 0.48          \n",
      "Testing in progress @ step 639 loss 1.63133 accuracy 0.29          \n",
      "Training in progress @ step 659 loss 1.28601 accuracy 0.5          \n",
      "Testing in progress @ step 659 loss 1.27028 accuracy 0.54          \n",
      "Training in progress @ step 679 loss 1.34397 accuracy 0.46          \n",
      "Testing in progress @ step 679 loss 1.49995 accuracy 0.32          \n",
      "Training in progress @ step 699 loss 1.33476 accuracy 0.48          \n",
      "Testing in progress @ step 699 loss 1.21273 accuracy 0.58          \n",
      "saved @ weights/toynet-699\n",
      "Training in progress @ step 719 loss 1.24346 accuracy 0.54          \n",
      "Testing in progress @ step 719 loss 1.32053 accuracy 0.45          \n",
      "Training in progress @ step 739 loss 1.35787 accuracy 0.42          \n",
      "Testing in progress @ step 739 loss 1.32251 accuracy 0.52          \n",
      "Training in progress @ step 759 loss 1.45005 accuracy 0.32          \n",
      "Testing in progress @ step 759 loss 1.41197 accuracy 0.45          \n",
      "Training in progress @ step 779 loss 1.54981 accuracy 0.42          \n",
      "Testing in progress @ step 779 loss 1.47186 accuracy 0.38          \n",
      "Training in progress @ step 799 loss 1.28402 accuracy 0.42          \n",
      "Testing in progress @ step 799 loss 1.42321 accuracy 0.4          \n",
      "saved @ weights/toynet-799\n",
      "Training in progress @ step 819 loss 1.39536 accuracy 0.42          \n",
      "Testing in progress @ step 819 loss 1.38358 accuracy 0.42          \n",
      "Training in progress @ step 839 loss 1.49415 accuracy 0.3          \n",
      "Testing in progress @ step 839 loss 1.3798 accuracy 0.42          \n",
      "Training in progress @ step 859 loss 1.43467 accuracy 0.42          \n",
      "Testing in progress @ step 859 loss 1.39729 accuracy 0.42          \n",
      "Training in progress @ step 879 loss 1.38153 accuracy 0.42          \n",
      "Testing in progress @ step 879 loss 1.38065 accuracy 0.41          \n",
      "Training in progress @ step 899 loss 1.50392 accuracy 0.3          \n",
      "Testing in progress @ step 899 loss 1.32828 accuracy 0.41          \n",
      "saved @ weights/toynet-899\n",
      "Training in progress @ step 919 loss 1.33586 accuracy 0.44          \n",
      "Testing in progress @ step 919 loss 1.36615 accuracy 0.45          \n",
      "Training in progress @ step 939 loss 1.475 accuracy 0.38          \n",
      "Testing in progress @ step 939 loss 1.29647 accuracy 0.5          \n",
      "Training in progress @ step 959 loss 1.56009 accuracy 0.34          \n",
      "Testing in progress @ step 959 loss 1.38867 accuracy 0.43          \n",
      "Training in progress @ step 979 loss 1.14253 accuracy 0.56          \n",
      "Testing in progress @ step 979 loss 1.4243 accuracy 0.38          \n",
      "Training in progress @ step 999 loss 1.23462 accuracy 0.5          \n",
      "Testing in progress @ step 999 loss 1.42568 accuracy 0.38          \n",
      "saved @ weights/toynet-999\n",
      "Training in progress @ step 1019 loss 1.75675 accuracy 0.24          \n",
      "Testing in progress @ step 1019 loss 1.40803 accuracy 0.36          \n",
      "Training in progress @ step 1039 loss 1.35704 accuracy 0.42          \n",
      "Testing in progress @ step 1039 loss 1.44127 accuracy 0.38          \n",
      "Training in progress @ step 1059 loss 1.21828 accuracy 0.48          \n",
      "Testing in progress @ step 1059 loss 1.5003 accuracy 0.36          \n",
      "Training in progress @ step 1079 loss 1.44313 accuracy 0.44          \n",
      "Testing in progress @ step 1079 loss 1.34288 accuracy 0.42          \n",
      "Training in progress @ step 1099 loss 1.40949 accuracy 0.34          \n",
      "Testing in progress @ step 1099 loss 1.28814 accuracy 0.48          \n",
      "saved @ weights/toynet-1099\n",
      "Training in progress @ step 1119 loss 1.59756 accuracy 0.3          \n",
      "Testing in progress @ step 1119 loss 1.14942 accuracy 0.56          \n",
      "Training in progress @ step 1139 loss 1.3092 accuracy 0.52          \n",
      "Testing in progress @ step 1139 loss 1.36258 accuracy 0.48          \n",
      "Training in progress @ step 1159 loss 1.14995 accuracy 0.5          \n",
      "Testing in progress @ step 1159 loss 1.36977 accuracy 0.4          \n",
      "Training in progress @ step 1179 loss 1.40494 accuracy 0.42          \n",
      "Testing in progress @ step 1179 loss 1.55631 accuracy 0.3          \n",
      "Training in progress @ step 1199 loss 1.22669 accuracy 0.5          \n",
      "Testing in progress @ step 1199 loss 1.28139 accuracy 0.46          \n",
      "saved @ weights/toynet-1199\n",
      "Training in progress @ step 1219 loss 1.63273 accuracy 0.32          \n",
      "Testing in progress @ step 1219 loss 1.35659 accuracy 0.4          \n",
      "Training in progress @ step 1239 loss 1.11035 accuracy 0.56          \n",
      "Testing in progress @ step 1239 loss 1.01814 accuracy 0.61          \n",
      "Training in progress @ step 1259 loss 1.47201 accuracy 0.38          \n",
      "Testing in progress @ step 1259 loss 1.26652 accuracy 0.47          \n",
      "Training in progress @ step 1279 loss 0.959723 accuracy 0.6          \n",
      "Testing in progress @ step 1279 loss 1.27624 accuracy 0.47          \n",
      "Training in progress @ step 1299 loss 1.03533 accuracy 0.58          \n",
      "Testing in progress @ step 1299 loss 1.32861 accuracy 0.46          \n",
      "saved @ weights/toynet-1299\n",
      "Training in progress @ step 1319 loss 1.10802 accuracy 0.62          \n",
      "Testing in progress @ step 1319 loss 1.34189 accuracy 0.42          \n",
      "Training in progress @ step 1339 loss 1.16607 accuracy 0.54          \n",
      "Testing in progress @ step 1339 loss 1.21847 accuracy 0.49          \n",
      "Training in progress @ step 1359 loss 1.30018 accuracy 0.46          \n",
      "Testing in progress @ step 1359 loss 1.32691 accuracy 0.43          \n",
      "Training in progress @ step 1379 loss 1.16315 accuracy 0.54          \n",
      "Testing in progress @ step 1379 loss 1.3594 accuracy 0.47          \n",
      "Training in progress @ step 1399 loss 1.21976 accuracy 0.58          \n",
      "Testing in progress @ step 1399 loss 1.26826 accuracy 0.46          \n",
      "saved @ weights/toynet-1399\n",
      "Training in progress @ step 1419 loss 1.22971 accuracy 0.5          \n",
      "Testing in progress @ step 1419 loss 1.36856 accuracy 0.44          \n",
      "Training in progress @ step 1439 loss 1.11646 accuracy 0.56          \n",
      "Testing in progress @ step 1439 loss 1.39475 accuracy 0.5          \n",
      "Training in progress @ step 1459 loss 1.10046 accuracy 0.52          \n",
      "Testing in progress @ step 1459 loss 1.28802 accuracy 0.47          \n",
      "Training in progress @ step 1479 loss 1.3629 accuracy 0.38          \n",
      "Testing in progress @ step 1479 loss 1.26074 accuracy 0.49          \n",
      "Training in progress @ step 1499 loss 1.32291 accuracy 0.42          \n",
      "Testing in progress @ step 1499 loss 1.33066 accuracy 0.46          \n",
      "saved @ weights/toynet-1499\n",
      "Training in progress @ step 1519 loss 1.35339 accuracy 0.42          \n",
      "Testing in progress @ step 1519 loss 1.20923 accuracy 0.52          \n",
      "Training in progress @ step 1539 loss 1.2372 accuracy 0.46          \n",
      "Testing in progress @ step 1539 loss 1.32964 accuracy 0.44          \n",
      "Training in progress @ step 1559 loss 1.2123 accuracy 0.5          \n",
      "Testing in progress @ step 1559 loss 1.38643 accuracy 0.46          \n",
      "Training in progress @ step 1579 loss 1.20874 accuracy 0.46          \n",
      "Testing in progress @ step 1579 loss 1.19228 accuracy 0.52          \n",
      "Training in progress @ step 1599 loss 1.5643 accuracy 0.32          \n",
      "Testing in progress @ step 1599 loss 1.31937 accuracy 0.49          \n",
      "saved @ weights/toynet-1599\n",
      "Training in progress @ step 1619 loss 1.30896 accuracy 0.42          \n",
      "Testing in progress @ step 1619 loss 1.22175 accuracy 0.48          \n",
      "Training in progress @ step 1639 loss 1.22795 accuracy 0.52          \n",
      "Testing in progress @ step 1639 loss 1.20655 accuracy 0.5          \n",
      "Training in progress @ step 1659 loss 1.40815 accuracy 0.4          \n",
      "Testing in progress @ step 1659 loss 1.3315 accuracy 0.42          \n",
      "Training in progress @ step 1679 loss 1.30008 accuracy 0.44          \n",
      "Testing in progress @ step 1679 loss 1.29789 accuracy 0.52          \n",
      "Training in progress @ step 1699 loss 1.09675 accuracy 0.54          \n",
      "Testing in progress @ step 1699 loss 1.31134 accuracy 0.48          \n",
      "saved @ weights/toynet-1699\n",
      "Training in progress @ step 1719 loss 1.07415 accuracy 0.56          \n",
      "Testing in progress @ step 1719 loss 1.41121 accuracy 0.37          \n",
      "Training in progress @ step 1739 loss 1.2409 accuracy 0.5          \n",
      "Testing in progress @ step 1739 loss 1.32115 accuracy 0.46          \n",
      "Training in progress @ step 1759 loss 1.40083 accuracy 0.42          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing in progress @ step 1759 loss 1.36045 accuracy 0.42          \n",
      "Training in progress @ step 1779 loss 1.31742 accuracy 0.44          \n",
      "Testing in progress @ step 1779 loss 1.15408 accuracy 0.51          \n",
      "Training in progress @ step 1799 loss 1.57415 accuracy 0.44          \n",
      "Testing in progress @ step 1799 loss 1.44827 accuracy 0.35          \n",
      "saved @ weights/toynet-1799\n",
      "Training in progress @ step 1819 loss 1.15384 accuracy 0.52          \n",
      "Testing in progress @ step 1819 loss 1.23731 accuracy 0.56          \n",
      "Training in progress @ step 1839 loss 1.34757 accuracy 0.38          \n",
      "Testing in progress @ step 1839 loss 1.34269 accuracy 0.42          \n",
      "Training in progress @ step 1859 loss 1.47447 accuracy 0.44          \n",
      "Testing in progress @ step 1859 loss 1.35923 accuracy 0.37          \n",
      "Training in progress @ step 1879 loss 1.35056 accuracy 0.5          \n",
      "Testing in progress @ step 1879 loss 1.42168 accuracy 0.43          \n",
      "Training in progress @ step 1899 loss 1.19593 accuracy 0.52          \n",
      "Testing in progress @ step 1899 loss 1.29576 accuracy 0.43          \n",
      "saved @ weights/toynet-1899\n",
      "Training in progress @ step 1919 loss 1.32414 accuracy 0.44          \n",
      "Testing in progress @ step 1919 loss 1.19566 accuracy 0.48          \n",
      "Training in progress @ step 1939 loss 1.40356 accuracy 0.38          \n",
      "Testing in progress @ step 1939 loss 1.10621 accuracy 0.5          \n",
      "Training in progress @ step 1959 loss 1.38538 accuracy 0.38          \n",
      "Testing in progress @ step 1959 loss 1.29307 accuracy 0.4          \n",
      "Training in progress @ step 1979 loss 1.25297 accuracy 0.46          \n",
      "Testing in progress @ step 1979 loss 1.47508 accuracy 0.45          \n",
      "Training in progress @ step 1999 loss 1.10651 accuracy 0.54          \n",
      "Testing in progress @ step 1999 loss 1.43318 accuracy 0.48          \n",
      "saved @ weights/toynet-1999\n",
      "Training in progress @ step 2019 loss 1.13924 accuracy 0.46          \n",
      "Testing in progress @ step 2019 loss 1.45149 accuracy 0.43          \n",
      "Training in progress @ step 2039 loss 1.20708 accuracy 0.52          \n",
      "Testing in progress @ step 2039 loss 1.12436 accuracy 0.54          \n",
      "Training in progress @ step 2059 loss 1.24084 accuracy 0.48          \n",
      "Testing in progress @ step 2059 loss 1.15291 accuracy 0.5          \n",
      "Training in progress @ step 2079 loss 1.09611 accuracy 0.58          \n",
      "Testing in progress @ step 2079 loss 1.35684 accuracy 0.52          \n",
      "Training in progress @ step 2099 loss 1.36621 accuracy 0.42          \n",
      "Testing in progress @ step 2099 loss 1.22794 accuracy 0.46          \n",
      "saved @ weights/toynet-2099\n",
      "Training in progress @ step 2119 loss 1.24009 accuracy 0.56          \n",
      "Testing in progress @ step 2119 loss 1.3916 accuracy 0.46          \n",
      "Training in progress @ step 2139 loss 1.38259 accuracy 0.4          \n",
      "Testing in progress @ step 2139 loss 1.24296 accuracy 0.49          \n",
      "Training in progress @ step 2159 loss 1.23877 accuracy 0.42          \n",
      "Testing in progress @ step 2159 loss 1.10523 accuracy 0.54          \n",
      "Training in progress @ step 2179 loss 1.16822 accuracy 0.48          \n",
      "Testing in progress @ step 2179 loss 1.30721 accuracy 0.49          \n",
      "Training in progress @ step 2199 loss 1.31275 accuracy 0.42          \n",
      "Testing in progress @ step 2199 loss 1.30498 accuracy 0.49          \n",
      "saved @ weights/toynet-2199\n",
      "Training in progress @ step 2219 loss 1.16553 accuracy 0.5          \n",
      "Testing in progress @ step 2219 loss 1.41132 accuracy 0.41          \n",
      "Training in progress @ step 2239 loss 1.23251 accuracy 0.48          \n",
      "Testing in progress @ step 2239 loss 1.25666 accuracy 0.51          \n",
      "Training in progress @ step 2259 loss 1.50687 accuracy 0.48          \n",
      "Testing in progress @ step 2259 loss 1.46532 accuracy 0.41          \n",
      "Training in progress @ step 2279 loss 1.22819 accuracy 0.46          \n",
      "Testing in progress @ step 2279 loss 1.29717 accuracy 0.46          \n",
      "Training in progress @ step 2299 loss 1.25599 accuracy 0.42          \n",
      "Testing in progress @ step 2299 loss 1.28089 accuracy 0.47          \n",
      "saved @ weights/toynet-2299\n",
      "Training in progress @ step 2319 loss 1.34555 accuracy 0.4          \n",
      "Testing in progress @ step 2319 loss 1.27846 accuracy 0.47          \n",
      "Training in progress @ step 2339 loss 1.25334 accuracy 0.44          \n",
      "Testing in progress @ step 2339 loss 1.22018 accuracy 0.5          \n",
      "Training in progress @ step 2359 loss 1.37801 accuracy 0.34          \n",
      "Testing in progress @ step 2359 loss 1.29497 accuracy 0.42          \n",
      "Training in progress @ step 2379 loss 1.28552 accuracy 0.48          \n",
      "Testing in progress @ step 2379 loss 1.16077 accuracy 0.57          \n",
      "Training in progress @ step 2399 loss 1.27105 accuracy 0.42          \n",
      "Testing in progress @ step 2399 loss 1.34566 accuracy 0.46          \n",
      "saved @ weights/toynet-2399\n",
      "Training in progress @ step 2419 loss 1.28439 accuracy 0.44          \n",
      "Testing in progress @ step 2419 loss 1.29774 accuracy 0.44          \n",
      "Training in progress @ step 2439 loss 1.13568 accuracy 0.5          \n",
      "Testing in progress @ step 2439 loss 1.16471 accuracy 0.52          \n",
      "Training in progress @ step 2459 loss 1.19553 accuracy 0.56          \n",
      "Testing in progress @ step 2459 loss 1.32929 accuracy 0.49          \n",
      "Training in progress @ step 2479 loss 1.3844 accuracy 0.42          \n",
      "Testing in progress @ step 2479 loss 1.33151 accuracy 0.41          \n",
      "Training in progress @ step 2499 loss 1.39353 accuracy 0.32          \n",
      "Testing in progress @ step 2499 loss 1.35965 accuracy 0.39          \n",
      "saved @ weights/toynet-2499\n",
      "Training in progress @ step 2519 loss 1.17921 accuracy 0.54          \n",
      "Testing in progress @ step 2519 loss 1.29219 accuracy 0.51          \n",
      "Training in progress @ step 2539 loss 1.16891 accuracy 0.44          \n",
      "Testing in progress @ step 2539 loss 1.24513 accuracy 0.46          \n",
      "Training in progress @ step 2559 loss 1.20968 accuracy 0.48          \n",
      "Testing in progress @ step 2559 loss 1.18601 accuracy 0.54          \n",
      "Training in progress @ step 2579 loss 1.0199 accuracy 0.7          \n",
      "Testing in progress @ step 2579 loss 1.32612 accuracy 0.53          \n",
      "Training in progress @ step 2599 loss 1.19038 accuracy 0.56          \n",
      "Testing in progress @ step 2599 loss 1.02409 accuracy 0.63          \n",
      "saved @ weights/toynet-2599\n",
      "Training in progress @ step 2619 loss 0.914265 accuracy 0.74          \n",
      "Testing in progress @ step 2619 loss 1.0348 accuracy 0.63          \n",
      "Training in progress @ step 2639 loss 0.905937 accuracy 0.66          \n",
      "Testing in progress @ step 2639 loss 1.02448 accuracy 0.6          \n",
      "Training in progress @ step 2659 loss 1.10555 accuracy 0.54          \n",
      "Testing in progress @ step 2659 loss 1.22312 accuracy 0.59          \n",
      "Training in progress @ step 2679 loss 1.18222 accuracy 0.46          \n",
      "Testing in progress @ step 2679 loss 1.02361 accuracy 0.61          \n",
      "Training in progress @ step 2699 loss 1.08237 accuracy 0.54          \n",
      "Testing in progress @ step 2699 loss 1.03197 accuracy 0.67          \n",
      "saved @ weights/toynet-2699\n",
      "Training in progress @ step 2719 loss 0.892575 accuracy 0.72          \n",
      "Testing in progress @ step 2719 loss 1.03459 accuracy 0.59          \n",
      "Training in progress @ step 2739 loss 0.907834 accuracy 0.64          \n",
      "Testing in progress @ step 2739 loss 0.963836 accuracy 0.6          \n",
      "Training in progress @ step 2759 loss 1.12895 accuracy 0.56          \n",
      "Testing in progress @ step 2759 loss 0.99982 accuracy 0.64          \n",
      "Training in progress @ step 2779 loss 0.990316 accuracy 0.66          \n",
      "Testing in progress @ step 2779 loss 1.02595 accuracy 0.62          \n",
      "Training in progress @ step 2799 loss 1.136 accuracy 0.54          \n",
      "Testing in progress @ step 2799 loss 1.13477 accuracy 0.58          \n",
      "saved @ weights/toynet-2799\n",
      "Training in progress @ step 2819 loss 1.07206 accuracy 0.62          \n",
      "Testing in progress @ step 2819 loss 1.28559 accuracy 0.6          \n",
      "Training in progress @ step 2839 loss 0.912222 accuracy 0.6          \n",
      "Testing in progress @ step 2839 loss 1.1063 accuracy 0.57          \n",
      "Training in progress @ step 2859 loss 1.09191 accuracy 0.58          \n",
      "Testing in progress @ step 2859 loss 1.05456 accuracy 0.62          \n",
      "Training in progress @ step 2879 loss 1.02496 accuracy 0.64          \n",
      "Testing in progress @ step 2879 loss 1.02289 accuracy 0.59          \n",
      "Training in progress @ step 2899 loss 0.840538 accuracy 0.7          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing in progress @ step 2899 loss 1.18955 accuracy 0.61          \n",
      "saved @ weights/toynet-2899\n",
      "Training in progress @ step 2919 loss 0.977047 accuracy 0.68          \n",
      "Testing in progress @ step 2919 loss 1.28696 accuracy 0.55          \n",
      "Training in progress @ step 2939 loss 1.26222 accuracy 0.56          \n",
      "Testing in progress @ step 2939 loss 1.1124 accuracy 0.63          \n",
      "Training in progress @ step 2959 loss 0.980403 accuracy 0.62          \n",
      "Testing in progress @ step 2959 loss 1.13197 accuracy 0.59          \n",
      "Training in progress @ step 2979 loss 0.845093 accuracy 0.58          \n",
      "Testing in progress @ step 2979 loss 0.845257 accuracy 0.72          \n",
      "Training in progress @ step 2999 loss 1.08444 accuracy 0.58          \n",
      "Testing in progress @ step 2999 loss 0.850927 accuracy 0.72          \n",
      "saved @ weights/toynet-2999\n",
      "Training in progress @ step 3019 loss 0.782109 accuracy 0.7          \n",
      "Testing in progress @ step 3019 loss 0.972546 accuracy 0.6          \n",
      "Training in progress @ step 3039 loss 0.807289 accuracy 0.72          \n",
      "Testing in progress @ step 3039 loss 1.56879 accuracy 0.45          \n",
      "Training in progress @ step 3059 loss 0.956611 accuracy 0.66          \n",
      "Testing in progress @ step 3059 loss 1.07731 accuracy 0.61          \n",
      "Training in progress @ step 3079 loss 1.19789 accuracy 0.56          \n",
      "Testing in progress @ step 3079 loss 0.935651 accuracy 0.63          \n",
      "Training in progress @ step 3099 loss 1.05193 accuracy 0.6          \n",
      "Testing in progress @ step 3099 loss 0.921882 accuracy 0.65          \n",
      "saved @ weights/toynet-3099\n",
      "Training in progress @ step 3119 loss 0.988527 accuracy 0.6          \n",
      "Testing in progress @ step 3119 loss 0.995996 accuracy 0.64          \n",
      "Training in progress @ step 3139 loss 0.906325 accuracy 0.68          \n",
      "Testing in progress @ step 3139 loss 1.14295 accuracy 0.51          \n",
      "Training in progress @ step 3159 loss 0.887217 accuracy 0.72          \n",
      "Testing in progress @ step 3159 loss 1.20886 accuracy 0.61          \n",
      "Training in progress @ step 3179 loss 0.880853 accuracy 0.68          \n",
      "Testing in progress @ step 3179 loss 0.950432 accuracy 0.64          \n",
      "Training in progress @ step 3199 loss 0.886587 accuracy 0.7          \n",
      "Testing in progress @ step 3199 loss 1.03546 accuracy 0.68          \n",
      "saved @ weights/toynet-3199\n",
      "Training in progress @ step 3219 loss 0.708567 accuracy 0.74          \n",
      "Testing in progress @ step 3219 loss 1.02448 accuracy 0.6          \n",
      "Training in progress @ step 3239 loss 0.816711 accuracy 0.74          \n",
      "Testing in progress @ step 3239 loss 1.41907 accuracy 0.55          \n",
      "Training in progress @ step 3259 loss 0.958465 accuracy 0.64          \n",
      "Testing in progress @ step 3259 loss 1.06177 accuracy 0.58          \n",
      "Training in progress @ step 3279 loss 0.934965 accuracy 0.7          \n",
      "Testing in progress @ step 3279 loss 1.14993 accuracy 0.61          \n",
      "Training in progress @ step 3299 loss 0.876664 accuracy 0.64          \n",
      "Testing in progress @ step 3299 loss 0.830728 accuracy 0.7          \n",
      "saved @ weights/toynet-3299\n",
      "Training in progress @ step 3319 loss 0.899346 accuracy 0.62          \n",
      "Testing in progress @ step 3319 loss 0.974203 accuracy 0.63          \n",
      "Training in progress @ step 3339 loss 0.8549 accuracy 0.68          \n",
      "Testing in progress @ step 3339 loss 1.0486 accuracy 0.67          \n",
      "Training in progress @ step 3359 loss 0.778451 accuracy 0.76          \n",
      "Testing in progress @ step 3359 loss 0.938183 accuracy 0.64          \n",
      "Training in progress @ step 3379 loss 0.721426 accuracy 0.78          \n",
      "Testing in progress @ step 3379 loss 0.942979 accuracy 0.58          \n",
      "Training in progress @ step 3399 loss 0.844021 accuracy 0.7          \n",
      "Testing in progress @ step 3399 loss 1.22543 accuracy 0.55          \n",
      "saved @ weights/toynet-3399\n",
      "Training in progress @ step 3419 loss 0.93157 accuracy 0.6          \n",
      "Testing in progress @ step 3419 loss 0.985303 accuracy 0.59          \n",
      "Training in progress @ step 3439 loss 0.956273 accuracy 0.6          \n",
      "Testing in progress @ step 3439 loss 1.35173 accuracy 0.49          \n",
      "Training in progress @ step 3459 loss 0.805594 accuracy 0.68          \n",
      "Testing in progress @ step 3459 loss 1.01814 accuracy 0.65          \n",
      "Training in progress @ step 3479 loss 0.965058 accuracy 0.66          \n",
      "Testing in progress @ step 3479 loss 0.895926 accuracy 0.67          \n",
      "Training in progress @ step 3499 loss 0.931219 accuracy 0.56          \n",
      "Testing in progress @ step 3499 loss 0.939264 accuracy 0.62          \n",
      "saved @ weights/toynet-3499\n",
      "Training in progress @ step 3519 loss 0.923523 accuracy 0.6          \n",
      "Testing in progress @ step 3519 loss 1.13884 accuracy 0.55          \n",
      "Training in progress @ step 3539 loss 0.603205 accuracy 0.8          \n",
      "Testing in progress @ step 3539 loss 1.23255 accuracy 0.55          \n",
      "Training in progress @ step 3559 loss 0.895019 accuracy 0.68          \n",
      "Testing in progress @ step 3559 loss 1.05977 accuracy 0.62          \n",
      "Training in progress @ step 3579 loss 1.16642 accuracy 0.56          \n",
      "Testing in progress @ step 3579 loss 0.993485 accuracy 0.69          \n",
      "Training in progress @ step 3599 loss 1.17414 accuracy 0.56          \n",
      "Testing in progress @ step 3599 loss 1.25358 accuracy 0.52          \n",
      "saved @ weights/toynet-3599\n",
      "Training in progress @ step 3619 loss 0.808573 accuracy 0.72          \n",
      "Testing in progress @ step 3619 loss 0.788255 accuracy 0.77          \n",
      "Training in progress @ step 3639 loss 1.05184 accuracy 0.64          \n",
      "Testing in progress @ step 3639 loss 1.1351 accuracy 0.58          \n",
      "Training in progress @ step 3659 loss 0.861347 accuracy 0.72          \n",
      "Testing in progress @ step 3659 loss 1.21919 accuracy 0.57          \n",
      "Training in progress @ step 3679 loss 0.869561 accuracy 0.7          \n",
      "Testing in progress @ step 3679 loss 0.866228 accuracy 0.67          \n",
      "Training in progress @ step 3699 loss 1.11613 accuracy 0.48          \n",
      "Testing in progress @ step 3699 loss 1.08111 accuracy 0.69          \n",
      "saved @ weights/toynet-3699\n",
      "Training in progress @ step 3719 loss 0.868582 accuracy 0.7          \n",
      "Testing in progress @ step 3719 loss 0.934805 accuracy 0.68          \n",
      "Training in progress @ step 3739 loss 0.805072 accuracy 0.68          \n",
      "Testing in progress @ step 3739 loss 1.20985 accuracy 0.57          \n",
      "Training in progress @ step 3759 loss 0.955856 accuracy 0.64          \n",
      "Testing in progress @ step 3759 loss 0.975188 accuracy 0.63          \n",
      "Training in progress @ step 3779 loss 1.05078 accuracy 0.56          \n",
      "Testing in progress @ step 3779 loss 1.03399 accuracy 0.62          \n",
      "Training in progress @ step 3799 loss 0.808481 accuracy 0.68          \n",
      "Testing in progress @ step 3799 loss 0.912896 accuracy 0.64          \n",
      "saved @ weights/toynet-3799\n",
      "Training in progress @ step 3819 loss 0.763038 accuracy 0.7          \n",
      "Testing in progress @ step 3819 loss 1.05865 accuracy 0.62          \n",
      "Training in progress @ step 3839 loss 1.12601 accuracy 0.58          \n",
      "Testing in progress @ step 3839 loss 0.939801 accuracy 0.63          \n",
      "Training in progress @ step 3859 loss 0.997902 accuracy 0.52          \n",
      "Testing in progress @ step 3859 loss 1.1353 accuracy 0.65          \n",
      "Training in progress @ step 3879 loss 0.801144 accuracy 0.7          \n",
      "Testing in progress @ step 3879 loss 1.11356 accuracy 0.58          \n",
      "Training in progress @ step 3899 loss 0.780597 accuracy 0.74          \n",
      "Testing in progress @ step 3899 loss 1.01715 accuracy 0.62          \n",
      "saved @ weights/toynet-3899\n",
      "Training in progress @ step 3919 loss 0.695485 accuracy 0.8          \n",
      "Testing in progress @ step 3919 loss 1.53106 accuracy 0.65          \n",
      "Training in progress @ step 3939 loss 1.04625 accuracy 0.64          \n",
      "Testing in progress @ step 3939 loss 1.16947 accuracy 0.58          \n",
      "Training in progress @ step 3959 loss 0.716861 accuracy 0.74          \n",
      "Testing in progress @ step 3959 loss 0.987587 accuracy 0.7          \n",
      "Training in progress @ step 3979 loss 0.701108 accuracy 0.74          \n",
      "Testing in progress @ step 3979 loss 0.907562 accuracy 0.69          \n",
      "Training in progress @ step 3999 loss 0.762456 accuracy 0.74          \n",
      "Testing in progress @ step 3999 loss 1.07283 accuracy 0.6          \n",
      "saved @ weights/toynet-3999\n",
      "Training in progress @ step 4019 loss 0.798218 accuracy 0.72          \n",
      "Testing in progress @ step 4019 loss 1.4138 accuracy 0.54          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress @ step 4039 loss 0.869528 accuracy 0.7          \n",
      "Testing in progress @ step 4039 loss 1.06138 accuracy 0.68          \n",
      "Training in progress @ step 4059 loss 0.876087 accuracy 0.62          \n",
      "Testing in progress @ step 4059 loss 1.07748 accuracy 0.6          \n",
      "Training in progress @ step 4079 loss 1.11291 accuracy 0.58          \n",
      "Testing in progress @ step 4079 loss 0.921137 accuracy 0.62          \n",
      "Training in progress @ step 4099 loss 0.735105 accuracy 0.72          \n",
      "Testing in progress @ step 4099 loss 1.16022 accuracy 0.58          \n",
      "saved @ weights/toynet-4099\n",
      "Training in progress @ step 4119 loss 0.669679 accuracy 0.76          \n",
      "Testing in progress @ step 4119 loss 0.904578 accuracy 0.67          \n",
      "Training in progress @ step 4139 loss 0.833822 accuracy 0.62          \n",
      "Testing in progress @ step 4139 loss 1.07333 accuracy 0.73          \n",
      "Training in progress @ step 4159 loss 0.859325 accuracy 0.66          \n",
      "Testing in progress @ step 4159 loss 1.07189 accuracy 0.61          \n",
      "Training in progress @ step 4179 loss 0.697317 accuracy 0.82          \n",
      "Testing in progress @ step 4179 loss 0.984725 accuracy 0.56          \n",
      "Training in progress @ step 4199 loss 1.10889 accuracy 0.5          \n",
      "Testing in progress @ step 4199 loss 1.14758 accuracy 0.62          \n",
      "saved @ weights/toynet-4199\n",
      "Training in progress @ step 4219 loss 0.848653 accuracy 0.68          \n",
      "Testing in progress @ step 4219 loss 1.04747 accuracy 0.64          \n",
      "Training in progress @ step 4239 loss 1.02426 accuracy 0.66          \n",
      "Testing in progress @ step 4239 loss 1.62632 accuracy 0.61          \n",
      "Training in progress @ step 4259 loss 0.763943 accuracy 0.74          \n",
      "Testing in progress @ step 4259 loss 0.916157 accuracy 0.62          \n",
      "Training in progress @ step 4279 loss 0.81513 accuracy 0.62          \n",
      "Testing in progress @ step 4279 loss 1.4475 accuracy 0.58          \n",
      "Training in progress @ step 4299 loss 0.743328 accuracy 0.68          \n",
      "Testing in progress @ step 4299 loss 0.98579 accuracy 0.64          \n",
      "saved @ weights/toynet-4299\n",
      "Training in progress @ step 4319 loss 1.04831 accuracy 0.58          \n",
      "Testing in progress @ step 4319 loss 0.857489 accuracy 0.73          \n",
      "Training in progress @ step 4339 loss 0.874941 accuracy 0.76          \n",
      "Testing in progress @ step 4339 loss 1.07279 accuracy 0.58          \n",
      "Training in progress @ step 4359 loss 1.49156 accuracy 0.56          \n",
      "Testing in progress @ step 4359 loss 1.11115 accuracy 0.61          \n",
      "Training in progress @ step 4379 loss 0.985179 accuracy 0.66          \n",
      "Testing in progress @ step 4379 loss 0.975968 accuracy 0.65          \n",
      "Training in progress @ step 4399 loss 0.76463 accuracy 0.72          \n",
      "Testing in progress @ step 4399 loss 0.821448 accuracy 0.69          \n",
      "saved @ weights/toynet-4399\n",
      "Training in progress @ step 4419 loss 0.862835 accuracy 0.7          \n",
      "Testing in progress @ step 4419 loss 0.792502 accuracy 0.74          \n",
      "Training in progress @ step 4439 loss 0.853085 accuracy 0.66          \n",
      "Testing in progress @ step 4439 loss 1.0382 accuracy 0.6          \n",
      "Training in progress @ step 4459 loss 0.881232 accuracy 0.64          \n",
      "Testing in progress @ step 4459 loss 0.900207 accuracy 0.67          \n",
      "Training in progress @ step 4479 loss 0.772701 accuracy 0.7          \n",
      "Testing in progress @ step 4479 loss 1.03532 accuracy 0.58          \n",
      "Training in progress @ step 4499 loss 0.71728 accuracy 0.72          \n",
      "Testing in progress @ step 4499 loss 0.819204 accuracy 0.73          \n",
      "saved @ weights/toynet-4499\n",
      "Training in progress @ step 4519 loss 0.735722 accuracy 0.74          \n",
      "Testing in progress @ step 4519 loss 1.03337 accuracy 0.7          \n",
      "Training in progress @ step 4539 loss 1.04081 accuracy 0.6          \n",
      "Testing in progress @ step 4539 loss 0.90222 accuracy 0.76          \n",
      "Training in progress @ step 4559 loss 0.817292 accuracy 0.66          \n",
      "Testing in progress @ step 4559 loss 0.972736 accuracy 0.61          \n",
      "Training in progress @ step 4579 loss 0.859414 accuracy 0.66          \n",
      "Testing in progress @ step 4579 loss 1.1407 accuracy 0.68          \n",
      "Training in progress @ step 4599 loss 0.80086 accuracy 0.64          \n",
      "Testing in progress @ step 4599 loss 1.04296 accuracy 0.64          \n",
      "saved @ weights/toynet-4599\n",
      "Training in progress @ step 4619 loss 1.02619 accuracy 0.56          \n",
      "Testing in progress @ step 4619 loss 1.05041 accuracy 0.55          \n",
      "Training in progress @ step 4639 loss 0.745665 accuracy 0.7          \n",
      "Testing in progress @ step 4639 loss 0.902933 accuracy 0.65          \n",
      "Training in progress @ step 4659 loss 1.0371 accuracy 0.6          \n",
      "Testing in progress @ step 4659 loss 1.05664 accuracy 0.64          \n",
      "Training in progress @ step 4679 loss 0.881162 accuracy 0.64          \n",
      "Testing in progress @ step 4679 loss 0.929256 accuracy 0.72          \n",
      "Training in progress @ step 4699 loss 0.851253 accuracy 0.68          \n",
      "Testing in progress @ step 4699 loss 0.944113 accuracy 0.62          \n",
      "saved @ weights/toynet-4699\n",
      "Training in progress @ step 4719 loss 0.677615 accuracy 0.76          \n",
      "Testing in progress @ step 4719 loss 1.05899 accuracy 0.63          \n",
      "Training in progress @ step 4739 loss 0.984966 accuracy 0.62          \n",
      "Testing in progress @ step 4739 loss 1.23542 accuracy 0.57          \n",
      "Training in progress @ step 4759 loss 0.800678 accuracy 0.62          \n",
      "Testing in progress @ step 4759 loss 1.21451 accuracy 0.64          \n",
      "Training in progress @ step 4779 loss 0.713391 accuracy 0.74          \n",
      "Testing in progress @ step 4779 loss 0.881837 accuracy 0.68          \n",
      "Training in progress @ step 4799 loss 0.708179 accuracy 0.82          \n",
      "Testing in progress @ step 4799 loss 0.975072 accuracy 0.64          \n",
      "saved @ weights/toynet-4799\n",
      "Training in progress @ step 4819 loss 1.03813 accuracy 0.56          \n",
      "Testing in progress @ step 4819 loss 0.815509 accuracy 0.72          \n",
      "Training in progress @ step 4839 loss 0.952589 accuracy 0.6          \n",
      "Testing in progress @ step 4839 loss 1.21499 accuracy 0.63          \n",
      "Training in progress @ step 4859 loss 0.836361 accuracy 0.74          \n",
      "Testing in progress @ step 4859 loss 0.975035 accuracy 0.64          \n",
      "Training in progress @ step 4879 loss 0.809618 accuracy 0.72          \n",
      "Testing in progress @ step 4879 loss 0.931493 accuracy 0.69          \n",
      "Training in progress @ step 4899 loss 0.733196 accuracy 0.7          \n",
      "Testing in progress @ step 4899 loss 1.03205 accuracy 0.66          \n",
      "saved @ weights/toynet-4899\n",
      "Training in progress @ step 4919 loss 0.818327 accuracy 0.7          \n",
      "Testing in progress @ step 4919 loss 0.986588 accuracy 0.59          \n",
      "Training in progress @ step 4939 loss 0.632603 accuracy 0.84          \n",
      "Testing in progress @ step 4939 loss 1.03022 accuracy 0.71          \n",
      "Training in progress @ step 4959 loss 0.730801 accuracy 0.68          \n",
      "Testing in progress @ step 4959 loss 1.10876 accuracy 0.67          \n",
      "Training in progress @ step 4979 loss 0.651404 accuracy 0.78          \n",
      "Testing in progress @ step 4979 loss 0.979593 accuracy 0.67          \n",
      "Training in progress @ step 4999 loss 0.689616 accuracy 0.78          \n",
      "Testing in progress @ step 4999 loss 1.10341 accuracy 0.62          \n",
      "saved @ weights/toynet-4999\n",
      "\n",
      "Run `tensorboard --logdir=log` in terminal to see the results.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 4: Run training loop\n",
    "#\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    train_data  = train_io.fetch_data('train_image').data()\n",
    "    train_label = train_io.fetch_data('train_label').data()\n",
    "\n",
    "    feed_dict = { data_tensor  : train_data,\n",
    "                  label_tensor : train_label }\n",
    "\n",
    "    loss, acc, _ = sess.run([cross_entropy, accuracy, train_step], feed_dict=feed_dict)\n",
    "\n",
    "    if (i+1)%SAVE_SUMMARY == 0:\n",
    "        # Save train log\n",
    "        sys.stdout.write('Training in progress @ step %d loss %g accuracy %g          \\n' % (i,loss,acc))\n",
    "        sys.stdout.flush()\n",
    "        s = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "        writer_train.add_summary(s,i)\n",
    "    \n",
    "        # Calculate & save test log\n",
    "        test_data  = test_io.fetch_data('test_image').data()\n",
    "        test_label = test_io.fetch_data('test_label').data()\n",
    "        feed_dict  = { data_tensor  : test_data,\n",
    "                       label_tensor : test_label }\n",
    "        loss, acc = sess.run([cross_entropy, accuracy], feed_dict=feed_dict)\n",
    "        sys.stdout.write('Testing in progress @ step %d loss %g accuracy %g          \\n' % (i,loss,acc))\n",
    "        sys.stdout.flush()\n",
    "        s = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "        writer_test.add_summary(s,i)\n",
    "        \n",
    "        test_io.next()\n",
    "\n",
    "    train_io.next()\n",
    "\n",
    "    if (i+1)%SAVE_WEIGHTS == 0:\n",
    "        ssf_path = saver.save(sess,'weights/toynet',global_step=i)\n",
    "        print('saved @',ssf_path)\n",
    "\n",
    "# inform log directory\n",
    "print()\n",
    "print('Run `tensorboard --logdir=%s` in terminal to see the results.' % LOGDIR)\n",
    "train_io.reset()\n",
    "test_io.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dell/anaconda3/bin/tensorboard\", line 10, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/home/dell/anaconda3/lib/python3.7/site-packages/tensorboard/main.py\", line 64, in run_main\n",
      "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
      "  File \"/home/dell/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 300, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/dell/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/dell/anaconda3/lib/python3.7/site-packages/tensorboard/program.py\", line 228, in main\n",
      "    server = self._make_server()\n",
      "  File \"/home/dell/anaconda3/lib/python3.7/site-packages/tensorboard/program.py\", line 309, in _make_server\n",
      "    self.assets_zip_provider)\n",
      "  File \"/home/dell/anaconda3/lib/python3.7/site-packages/tensorboard/backend/application.py\", line 161, in standard_tensorboard_wsgi\n",
      "    reload_task)\n",
      "  File \"/home/dell/anaconda3/lib/python3.7/site-packages/tensorboard/backend/application.py\", line 194, in TensorBoardWSGIApp\n",
      "    return TensorBoardWSGI(plugins, path_prefix)\n",
      "  File \"/home/dell/anaconda3/lib/python3.7/site-packages/tensorboard/backend/application.py\", line 245, in __init__\n",
      "    raise ValueError('Duplicate plugins for name %s' % plugin.plugin_name)\n",
      "ValueError: Duplicate plugins for name projector\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'tensorboard --logdir=log\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2370c51df499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tensorboard --logdir=log\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2350\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2352\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/dell/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'tensorboard --logdir=log\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tensorboard --logdir=log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
